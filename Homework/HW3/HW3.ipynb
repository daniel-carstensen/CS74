{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the cell below to import libraries needed for this HW. Please use the autograd numpy, otherwise you will have issues. Please remember to always use the np library for mathematical functions (e.g., np.log, np.exp, np.sum, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) [5 points] Implement the sigmod funcation discussed in class. The function takes a value, x, as input and returns the sigmoid function applied to the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) [20 points] Implement the logistic regression model and the cross entropy cost discussed in class. Note that the logistic regression model relies on the sigmoid function (which you have implemented above) and the linear  model (which you have implemented in HW2). You can use the linear model from HW2 for this problem. Similar to the least-squares cost from HW2, the cross entropy cost takes in as input an array of weights, w, an array of x's and an array of ys and return a float indicating the total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your linear model from HW2\n",
    "def model(x, w):\n",
    "    y_predicted = w[0] + np.dot(x, w[1])\n",
    "    return y_predicted\n",
    "\n",
    "#The logistic regression cross entropy cost\n",
    "def cross_entropy(w, x, y):\n",
    "    y_predicted = sigmoid(model(x, w))\n",
    "    cost_matrix = y * np.log(y_predicted) + (1 - y) * np.log(1 - y_predicted)\n",
    "    cost = - np.mean(cost_matrix)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) [2 points] Run the code below to read a data file. Plot a scatter plot of x vs y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f97faaf6430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvname = '2d_classification_data_v1_entropy.csv'\n",
    "data = np.loadtxt(csvname,delimiter = ',')\n",
    "x = data[:-1,:][0]\n",
    "y = data[-1:,:][0]\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) [10 points] Move the gradient descent function from HW2. Run the function using the cross_entropy cost and the x and y from above. The parameters should be set to: max_its=2000,w=[3.0,3.0 ], and alpha=1. Save the cost and weight history returned by the gradient descent function. Plot the cost history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##gradient descent from HW2\n",
    "def gradient_descent(g, alpha, max_its, w, x, y):\n",
    "    gradient = grad(g)\n",
    "    weight_history = []\n",
    "    cost_history = []\n",
    "    w_curr = w\n",
    "    if alpha == 'diminishing':\n",
    "        for i in range(max_its):\n",
    "            weight_history.append(w_curr)\n",
    "            cost_history.append(g(w_curr, x, y))\n",
    "            w_curr = w_curr - 1/(i+1) * gradient(w_curr, x, y)\n",
    "    else:\n",
    "        for i in range(max_its):\n",
    "            weight_history.append(w_curr)\n",
    "            cost_history.append(g(w_curr, x, y))\n",
    "            w_curr = w_curr - alpha * gradient(w_curr, x, y)\n",
    "    return weight_history, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97facdc940>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_history, cost_history = gradient_descent(cross_entropy, 1.0, 1500, np.array([3.0, 3.0]), x, y)\n",
    "plt.plot(cost_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) [10 points] Implement a logistic regression classifier that takes in the learned weights and x as input and returns the probability of the positive class (note that this is just the output of the sigmoid applied to the linear combination of the x and w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(learned_w,x):\n",
    "    positive_class_prob = sigmoid(model(learned_w, x))\n",
    "    return positive_class_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) [5 points] Use the learned weights from the last gradient descent run and the logistic regression function implemented above to plot the learned curve. You can use the linspace method (shown below) to generate a list of xs that you can use. You need to generate a y for each of the candidate xs using the logistic regression function and the learned weights. On the same figure, also plot the scatter plot from Q3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f97fada7dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = np.linspace(np.min(x),np.max(x))\n",
    "t = np.empty((s.size, 1))\n",
    "\n",
    "t = logistic_regression(s, weight_history[-1])\n",
    "\n",
    "plt.plot(s, t)\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7) [5 points] Slightly modify the logistic regression model above so that it returns a 1 or 0 based on the specified threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_modified(learned_w, x, threshold):\n",
    "    positive_class_prob = sigmoid(model(x, learned_w))\n",
    "    class_label = (positive_class_prob > threshold).astype(int)\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8) [15 points] Write a function (called evaluate) that takes in actual and predicted ys (for a binary classification problem) and return a confusion matrix and the accuracy. Use the modified logistic regression model and the evaluate function below to report the confusion matrix and accuracy for the x and y used for our training at a threshold of 0.5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_actual,y_pred):\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    for label_actual, label_pred in zip(y_actual, y_pred):\n",
    "        if label_actual == label_pred:\n",
    "            if label_actual == 1:\n",
    "                true_positive += 1\n",
    "            elif label_actual == 0:\n",
    "                true_negative += 1\n",
    "        elif label_actual != label_pred:\n",
    "            if label_actual == 1:\n",
    "                false_negative += 1\n",
    "            elif label_actual == 0:\n",
    "                false_positive += 1\n",
    "    accuracy = (true_positive + true_negative) / (false_positive + false_negative + true_positive + true_negative)\n",
    "    return false_positive, false_negative, true_positive, true_negative, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6, 0],\n",
       "        [0, 5]]),\n",
       " 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic_regression_modified(weight_history[-1], x, 0.5)\n",
    "\n",
    "false_positive, false_negative, true_positive, true_negative, accuracy = evaluate(y, y_pred)\n",
    "confusion_matrix = np.array([[true_positive, false_negative], [false_positive, true_negative]])\n",
    "\n",
    "confusion_matrix, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9) [20 points] Implement the perceptron cost function from the class (the softmax version). Note that the perceptron cost also uses the linear model (the model function from question 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_cost(w, x, y):    \n",
    "    y_pred = model(x, w)\n",
    "    cost_matrix = np.log(1 + np.exp(-y * y_pred))\n",
    "    cost = np.sum(cost_matrix)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10) [10 points] Run gradient descent function using the perceptron cost and the x and y from above and the parameters set to: max_its=2000,w=[1.0,1.0], and alpha=1.0. Save the cost and weight history returned by the gradient descent function. Plot the cost history. Which cost seems to do better on this dataset? Why do think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97faeb7fd0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y[y == 0] = -1\n",
    "weight_history, cost_history = gradient_descent(perceptron_cost, 1.0, 2000, np.array([1.0, 1.0]), x, y)\n",
    "plt.plot(cost_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron cost seems to do better than the cross entropy cost on this dataset as it coverges faster. This may be because of the different starting weights that are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest of these problems are for bonus points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11) [2 points]  The file 'heart.csv' has 304 lines, each one corresponding to a data point. Each row (i.e., data point), has several columns. Read the data file. Note that the first line is the header describing each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12) [2 points] Use the data above to set y to be the \"target\" and X to be the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, Length: 303, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.iloc[:,0:13]\n",
    "display(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13) [2 points] Run the code below to import the logistic regression and the train_test split functions from sklearn. Split your data into 80% train 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14) [5 points] Use sklearn to fit a logistic regression model on your training set. Use all the default parameter. Do not evaluate at this point. (You can find out about sklearn logistic regression here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcarstensen/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15) [5 points] Use the .predict_proba function of the logistic regression model that you have learned on your X_test. Note that the .predict_proba function returns an array of tuples where each element corresponds to the predicted probability for class 0 and 1 of the data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97375456, 0.02624544],\n",
       "       [0.99479458, 0.00520542],\n",
       "       [0.75886307, 0.24113693],\n",
       "       [0.99441036, 0.00558964],\n",
       "       [0.31056198, 0.68943802],\n",
       "       [0.04787452, 0.95212548],\n",
       "       [0.01299269, 0.98700731],\n",
       "       [0.06170593, 0.93829407],\n",
       "       [0.17426945, 0.82573055],\n",
       "       [0.14682718, 0.85317282],\n",
       "       [0.0381688 , 0.9618312 ],\n",
       "       [0.04222685, 0.95777315],\n",
       "       [0.09327428, 0.90672572],\n",
       "       [0.01732649, 0.98267351],\n",
       "       [0.37609513, 0.62390487],\n",
       "       [0.26490303, 0.73509697],\n",
       "       [0.23360773, 0.76639227],\n",
       "       [0.99256878, 0.00743122],\n",
       "       [0.34240625, 0.65759375],\n",
       "       [0.99126186, 0.00873814],\n",
       "       [0.89027615, 0.10972385],\n",
       "       [0.41795212, 0.58204788],\n",
       "       [0.04561412, 0.95438588],\n",
       "       [0.33714027, 0.66285973],\n",
       "       [0.9864765 , 0.0135235 ],\n",
       "       [0.91242231, 0.08757769],\n",
       "       [0.86085424, 0.13914576],\n",
       "       [0.98453493, 0.01546507],\n",
       "       [0.21716928, 0.78283072],\n",
       "       [0.3071095 , 0.6928905 ],\n",
       "       [0.08300677, 0.91699323],\n",
       "       [0.38017462, 0.61982538],\n",
       "       [0.65813032, 0.34186968],\n",
       "       [0.44934883, 0.55065117],\n",
       "       [0.7523551 , 0.2476449 ],\n",
       "       [0.27783039, 0.72216961],\n",
       "       [0.09276407, 0.90723593],\n",
       "       [0.19925056, 0.80074944],\n",
       "       [0.90410448, 0.09589552],\n",
       "       [0.96029474, 0.03970526],\n",
       "       [0.22413718, 0.77586282],\n",
       "       [0.28366015, 0.71633985],\n",
       "       [0.52017331, 0.47982669],\n",
       "       [0.9251205 , 0.0748795 ],\n",
       "       [0.62080736, 0.37919264],\n",
       "       [0.97206284, 0.02793716],\n",
       "       [0.25933925, 0.74066075],\n",
       "       [0.4764779 , 0.5235221 ],\n",
       "       [0.07355145, 0.92644855],\n",
       "       [0.9125886 , 0.0874114 ],\n",
       "       [0.24772202, 0.75227798],\n",
       "       [0.95790345, 0.04209655],\n",
       "       [0.18813037, 0.81186963],\n",
       "       [0.3568129 , 0.6431871 ],\n",
       "       [0.05142   , 0.94858   ],\n",
       "       [0.92201649, 0.07798351],\n",
       "       [0.96772123, 0.03227877],\n",
       "       [0.38774167, 0.61225833],\n",
       "       [0.04069611, 0.95930389],\n",
       "       [0.33709745, 0.66290255],\n",
       "       [0.95646788, 0.04353212]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.predict_proba(X_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16) [2 points] Filter the predicted probabilties from the last question to an array containing only the probabilites for class 1. I.e., you should no longer have tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02624544, 0.00520542, 0.24113693, 0.00558964, 0.68943802,\n",
       "       0.95212548, 0.98700731, 0.93829407, 0.82573055, 0.85317282,\n",
       "       0.9618312 , 0.95777315, 0.90672572, 0.98267351, 0.62390487,\n",
       "       0.73509697, 0.76639227, 0.00743122, 0.65759375, 0.00873814,\n",
       "       0.10972385, 0.58204788, 0.95438588, 0.66285973, 0.0135235 ,\n",
       "       0.08757769, 0.13914576, 0.01546507, 0.78283072, 0.6928905 ,\n",
       "       0.91699323, 0.61982538, 0.34186968, 0.55065117, 0.2476449 ,\n",
       "       0.72216961, 0.90723593, 0.80074944, 0.09589552, 0.03970526,\n",
       "       0.77586282, 0.71633985, 0.47982669, 0.0748795 , 0.37919264,\n",
       "       0.02793716, 0.74066075, 0.5235221 , 0.92644855, 0.0874114 ,\n",
       "       0.75227798, 0.04209655, 0.81186963, 0.6431871 , 0.94858   ,\n",
       "       0.07798351, 0.03227877, 0.61225833, 0.95930389, 0.66290255,\n",
       "       0.04353212])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = scores[:,1]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17) [8 points] Use the roc_curve function from sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) to plot the ROC curve for your predictions using the predicted probabilities for class 1 and your y_test (use the default parameters). Also, print out the thresholds generated by the roc_curve function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.98700731 0.98700731 0.90723593 0.90672572 0.80074944 0.78283072\n",
      " 0.75227798 0.74066075 0.72216961 0.71633985 0.66290255 0.66285973\n",
      " 0.58204788 0.55065117 0.47982669 0.09589552 0.08757769 0.00520542]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97fd6a30d0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, scores)\n",
    "print(thresholds)\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18) [2 points] Use the roc_auc_score function from sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) to report the AUC score using the exact same setup as the last question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9101731601731602"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
